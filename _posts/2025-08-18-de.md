---
layout: single
title: "견고한 데이터 엔지니어링 - 소스 시스템과 스토리지 평가"
categories: DataEngineering
tag: [서평]
search: true
typora-root-url: ../
sidebar:
  nav: "counts"








---



**[견고한 데이터 엔지니어링][견고한 데이터 엔지니어링 - 소스 시스템과 스토리지 평가](https://park-chanyeong.github.io)**
{: .notice--primary}

# 소스 데이터 시스템 평가

- **데이터의 본질적인 특징**은 무엇인가? (애플리케이션? IoT 장비?)
- 원천 시스템에서 데이터는 어떻게 **유지**되는가? (장기간 보관용 아카이빙? 일시적 사용 후 빠른 삭제?)
- 데이터는 어느 정도의 **속도**로 생성되는가? (초당 이벤트 수, 시간당 데이터 크기)
- 데이터 엔지니어는 출력 데이터에서 어느 정도의 **일관성**을 기대할 수 있는가?
  (예: 품질 검사 시 예상치 못한 null 값, 잘못된 포맷, 동일 데이터 불일치 빈도)
- **에러 발생 빈도**는 어느 정도인가?
- 데이터에 **중복**이 포함되지 않는가? (일정 수준 중복을 감수할 수 있는가?)
- 일부 데이터 값이 동시에 생성된 다른 메시지보다 **늦게 도착**할 수 있는가? (메시징 큐 사용 여부)
- 수집된 데이터의 **스키마**는 무엇인가?
  (데이터를 완벽히 이해하려면 여러 테이블/시스템 간 조인이 필요한가?)
- **스키마 변경**(예: 새로운 컬럼 추가)이 발생하면 어떻게 대처하고, 이를 DS/DA 등 다운스트림 관계자에게 어떻게 전달할 것인가?
- 소스 데이터 시스템에서 데이터를 **가져오는 주기**는 어느 정도인가?
- **Stateful system**(상태가 있는 시스템, 예: 고객 계정 추적 DB)의 경우, 데이터는 스냅샷으로 제공되는가, 아니면 CDC(Change Data Capture) 이벤트로 제공되는가?
  - 변경은 어떤 방식으로 수행되며, 원천 DB에서 이를 어떻게 추적하는가?
- 원천 데이터 조회가 **성능**에 영향을 주는가? (리드온리 레플리카 활용 여부)
- 원천 시스템에 **업스트림 의존 관계**가 존재하는가?
- 늦거나 누락된 데이터를 확인하기 위해 **데이터 품질 검사**가 실시되는가?

# 스토리지 시스템 평가 (DW, Lakehouse, DL, DB)

- 스토리지 솔루션이 아키텍처에서 요구하는 **쓰기·읽기 속도**와 잘 맞는가?
- 스토리지가 다운스트림 프로세스의 **병목 현상**을 유발하지 않는가?
- 이 스토리지 기술이 작동하는 방식을 충분히 이해하고 있는가?
  → 최적 활용 중인가, 아니면 비효율적 사용(안티패턴)을 하고 있는가?
  - 예: 객체 스토리지에 **임의 접근(random access) 갱신**을 다량 적용하는 것은 큰 성능 오버헤드 유발
- 스토리지가 향후 **확장성**을 지원할 수 있는가? (총 용량, 읽기 속도, 쓰기 처리량)
- 다운스트림 사용자와의 **SLA(Service Level Agreement)** 요구사항을 충족할 수 있는가?
  (예: 데이터 분석가가 데이터 핸들링 가능한 상태로 제공되는가?)
- **스키마 진화, 데이터 흐름, 데이터 계보**를 추적하기 위한 **메타데이터**를 캡처하는가?
  → 메타데이터는 검색 가능성·활용성을 높이고, 프로젝트 변경을 간소화
- 단순 객체 스토리지인가, 아니면 **복잡한 쿼리 패턴(DW)**을 지원하는가?
- 스토리지 시스템의 **스키마 모델**은 무엇인가?
  (스키마 없음: 객체 스토리지 / 유연한 스키마: Cassandra / 강제 스키마: DW)
- **데이터 거버넌스** 측면에서 마스터 데이터, 골든 레코드, 품질, 계보를 어떻게 추적하는가?
- **법령 준수 및 데이터 주권(Data Sovereignty)**을 어떻게 충족하는가?

# Extract(데이터 수집) 단계 고려사항

- 수집 중인 데이터의 **사용 사례**는 무엇인가?
  (같은 데이터셋의 여러 버전을 생성하지 않고 재사용할 수 있는가?)
- 시스템이 데이터를 **안정적으로 생성·수집**하고 있는가? → 필요할 때 사용 가능한가?
- 수집 후 데이터의 **목적지**는 어디인가?
- 데이터에 얼마나 자주 **접근**해야 하는가?
- 데이터의 **크기**는 어느 정도인가?
- 데이터의 **형식**은 무엇인가?
- Raw data는 다운스트림에서 **바로 사용 가능한가**, 아니면 변환(Transform) 과정을 거쳐야 하는가?

## 배치 vs 스트리밍 수집 고려사항

- 실시간으로 데이터를 수집할 경우, 다운스트림 스토리지가 해당 **속도**를 감당할 수 있는가?
- **밀리초 단위** 실시간 수집이 필요한가, 아니면 **마이크로 배치**(매 분 단위 적재) 접근이 더 적합한가?
- 스트리밍 수집의 **사용 사례**와 **이점**은 무엇인가?
- 스트리밍 우선 접근은 단순 배치보다 **시간·비용·유지보수·다운타임·기회비용** 측면에서 더 많은 부담을 주지 않는가?
- 인프라 장애 발생 시, 스트리밍 파이프라인과 시스템은 **안정성·다중화**가 보장되는가?
- 사용 사례에 적합한 도구는 무엇인가?
  (예: 관리형 서비스 - **AWS Kinesis, GCP Pub/Sub, Dataflow** / 오픈소스 - **Kafka, Flink, Spark**)
